{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"happy pp\"):\n",
    "    frame=\"happy pp/\"+filename\n",
    "    \n",
    "    if frame=='happy pp/.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "    #print(filename)\n",
    "        i=Image.open(\"happy pp/\"+filename)\n",
    "        im=np.asarray(i)\n",
    "        data.append(im)\n",
    "        labels.append(filename+\"_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"scare pp\"):\n",
    "    frame=\"scare pp/\"+filename\n",
    "    \n",
    "    if frame=='scare pp/.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "    #print(filename)\n",
    "        i=Image.open(\"scare pp/\"+filename)\n",
    "        im=np.asarray(i)\n",
    "        data.append(im)\n",
    "        labels.append(filename+\"_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"sad pp\"):\n",
    "    frame=\"sad pp/\"+filename\n",
    "    \n",
    "    if frame=='sad pp/.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "    #print(filename)\n",
    "        i=Image.open(\"sad pp/\"+filename)\n",
    "        im=np.asarray(i)\n",
    "        data.append(im)\n",
    "        labels.append(filename+\"_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"angry pp\"):\n",
    "    frame=\"angry pp/\"+filename\n",
    "    \n",
    "    if frame=='angry pp/.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "    #print(filename)\n",
    "        i=Image.open(\"angry pp/\"+filename)\n",
    "        im=np.asarray(i)\n",
    "        data.append(im)\n",
    "        labels.append(filename+\"_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"neutral pp\"):\n",
    "    frame=\"neutral pp/\"+filename\n",
    "    \n",
    "    if frame=='neutral pp/.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "    #print(filename)\n",
    "        i=Image.open(\"neutral pp/\"+filename)\n",
    "        im=np.asarray(i)\n",
    "        data.append(im)\n",
    "        labels.append(filename+\"_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:,:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion=[]\n",
    "for i in range(len(labels)):\n",
    "    emotion.append(labels[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[]\n",
    "for i in range(len(data)):\n",
    "    d=data[i].flatten()\n",
    "    lis.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(lis, emotion)), \n",
    "               columns =['Image', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx,testx,trainy,testy=train_test_split(df[\"Image\"], df[\"Label\"], train_size=0.8,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=np.asarray(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=[]\n",
    "for i in range (len(trainx)):\n",
    "    trx=trainx[i].reshape((64,64))\n",
    "    traindata.append(trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=np.asarray(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4346, 64, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=traindata.reshape(len(traindata),64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=trainy.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=np.asarray(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, ..., 3, 3, 4], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  \n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation='relu',\n",
    "        input_shape=(64,64,1)\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "      \n",
    "      \n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_3_filter', min_value=64, max_value=256, step=16),\n",
    "        kernel_size=hp.Choice('conv_3_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "      \n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_4_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_4_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "      \n",
    "    \n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_5_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_5_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_6_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_6_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    \n",
    "    \n",
    "      \n",
    "      \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dense(6, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=20,directory='output',project_name=\"ProjectHP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 05m 04s]\n",
      "val_accuracy: 0.2896551787853241\n",
      "\n",
      "Best val_accuracy So Far: 0.3977011442184448\n",
      "Total elapsed time: 02h 28m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(traindata,trainy,epochs=3,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 58, 48)        76848     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 58, 58, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 58, 58, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 29, 29, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 29, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 144)       62352     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 48)        62256     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25, 25, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 25, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 80)          96080     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 48)          96048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 48)          192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 96)                18528     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 582       \n",
      "=================================================================\n",
      "Total params: 413,910\n",
      "Trainable params: 413,622\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40\n",
      "123/123 [==============================] - 110s 886ms/step - loss: 1.3320 - accuracy: 0.4497 - val_loss: 1.4646 - val_accuracy: 0.3885\n",
      "Epoch 5/40\n",
      "123/123 [==============================] - 104s 846ms/step - loss: 1.2561 - accuracy: 0.5089 - val_loss: 1.6355 - val_accuracy: 0.2621\n",
      "Epoch 6/40\n",
      "123/123 [==============================] - 104s 847ms/step - loss: 1.2130 - accuracy: 0.5203 - val_loss: 1.3990 - val_accuracy: 0.4138\n",
      "Epoch 7/40\n",
      "123/123 [==============================] - 105s 854ms/step - loss: 1.1609 - accuracy: 0.5520 - val_loss: 1.2738 - val_accuracy: 0.5034\n",
      "Epoch 8/40\n",
      "123/123 [==============================] - 105s 851ms/step - loss: 1.0960 - accuracy: 0.5596 - val_loss: 1.7637 - val_accuracy: 0.3494\n",
      "Epoch 9/40\n",
      "123/123 [==============================] - 106s 860ms/step - loss: 1.0467 - accuracy: 0.5882 - val_loss: 1.3091 - val_accuracy: 0.4966\n",
      "Epoch 10/40\n",
      "123/123 [==============================] - 88s 713ms/step - loss: 1.0207 - accuracy: 0.6009 - val_loss: 1.2895 - val_accuracy: 0.5034\n",
      "Epoch 11/40\n",
      "123/123 [==============================] - 1785s 15s/step - loss: 0.9799 - accuracy: 0.6312 - val_loss: 1.8472 - val_accuracy: 0.3954\n",
      "Epoch 12/40\n",
      "123/123 [==============================] - 88s 717ms/step - loss: 0.9240 - accuracy: 0.6511 - val_loss: 1.6596 - val_accuracy: 0.3310\n",
      "Epoch 13/40\n",
      "123/123 [==============================] - 86s 698ms/step - loss: 0.9174 - accuracy: 0.6515 - val_loss: 1.1503 - val_accuracy: 0.5333\n",
      "Epoch 14/40\n",
      "123/123 [==============================] - 154s 1s/step - loss: 0.8278 - accuracy: 0.6916 - val_loss: 1.1885 - val_accuracy: 0.5701\n",
      "Epoch 15/40\n",
      "123/123 [==============================] - 86s 700ms/step - loss: 0.7683 - accuracy: 0.7213 - val_loss: 1.1288 - val_accuracy: 0.5793\n",
      "Epoch 16/40\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.7208 - accuracy: 0.7401 - val_loss: 1.3589 - val_accuracy: 0.4966\n",
      "Epoch 17/40\n",
      "123/123 [==============================] - 85s 695ms/step - loss: 0.6705 - accuracy: 0.7456 - val_loss: 1.7103 - val_accuracy: 0.4644\n",
      "Epoch 18/40\n",
      "123/123 [==============================] - 103s 839ms/step - loss: 0.6541 - accuracy: 0.7556 - val_loss: 1.3978 - val_accuracy: 0.5356\n",
      "Epoch 19/40\n",
      "123/123 [==============================] - 106s 861ms/step - loss: 0.5479 - accuracy: 0.8020 - val_loss: 1.3200 - val_accuracy: 0.5678\n",
      "Epoch 20/40\n",
      "123/123 [==============================] - 106s 861ms/step - loss: 0.5188 - accuracy: 0.8095 - val_loss: 1.2565 - val_accuracy: 0.5540\n",
      "Epoch 21/40\n",
      "123/123 [==============================] - 103s 837ms/step - loss: 0.5046 - accuracy: 0.8176 - val_loss: 1.3677 - val_accuracy: 0.5563\n",
      "Epoch 22/40\n",
      "123/123 [==============================] - 100s 813ms/step - loss: 0.4635 - accuracy: 0.8251 - val_loss: 1.2540 - val_accuracy: 0.5701\n",
      "Epoch 23/40\n",
      "123/123 [==============================] - 88s 715ms/step - loss: 0.4541 - accuracy: 0.8169 - val_loss: 1.2980 - val_accuracy: 0.5954\n",
      "Epoch 24/40\n",
      "123/123 [==============================] - 87s 703ms/step - loss: 0.4310 - accuracy: 0.8427 - val_loss: 1.5851 - val_accuracy: 0.5609\n",
      "Epoch 25/40\n",
      "123/123 [==============================] - 85s 692ms/step - loss: 0.3471 - accuracy: 0.8709 - val_loss: 1.3128 - val_accuracy: 0.6092\n",
      "Epoch 26/40\n",
      "123/123 [==============================] - 85s 695ms/step - loss: 0.3179 - accuracy: 0.8874 - val_loss: 1.6079 - val_accuracy: 0.5586\n",
      "Epoch 27/40\n",
      "123/123 [==============================] - 105s 853ms/step - loss: 0.3023 - accuracy: 0.8960 - val_loss: 1.6427 - val_accuracy: 0.5770\n",
      "Epoch 28/40\n",
      "123/123 [==============================] - 100s 814ms/step - loss: 0.3174 - accuracy: 0.8860 - val_loss: 1.5130 - val_accuracy: 0.6322\n",
      "Epoch 29/40\n",
      "123/123 [==============================] - 112s 912ms/step - loss: 0.2696 - accuracy: 0.9081 - val_loss: 1.6016 - val_accuracy: 0.5793\n",
      "Epoch 30/40\n",
      "123/123 [==============================] - 116s 943ms/step - loss: 0.2802 - accuracy: 0.8995 - val_loss: 1.5120 - val_accuracy: 0.6184\n",
      "Epoch 31/40\n",
      "123/123 [==============================] - 110s 893ms/step - loss: 0.2556 - accuracy: 0.9084 - val_loss: 2.0620 - val_accuracy: 0.5356\n",
      "Epoch 32/40\n",
      "123/123 [==============================] - 113s 915ms/step - loss: 0.2295 - accuracy: 0.9195 - val_loss: 1.6061 - val_accuracy: 0.6023\n",
      "Epoch 33/40\n",
      "123/123 [==============================] - 104s 843ms/step - loss: 0.2306 - accuracy: 0.9181 - val_loss: 1.5763 - val_accuracy: 0.6138\n",
      "Epoch 34/40\n",
      "123/123 [==============================] - 113s 918ms/step - loss: 0.2511 - accuracy: 0.9095 - val_loss: 1.9008 - val_accuracy: 0.6092\n",
      "Epoch 35/40\n",
      "123/123 [==============================] - 118s 964ms/step - loss: 0.2148 - accuracy: 0.9181 - val_loss: 1.5532 - val_accuracy: 0.6207\n",
      "Epoch 36/40\n",
      "123/123 [==============================] - 111s 898ms/step - loss: 0.2495 - accuracy: 0.9164 - val_loss: 2.1659 - val_accuracy: 0.5356\n",
      "Epoch 37/40\n",
      "123/123 [==============================] - 115s 933ms/step - loss: 0.2083 - accuracy: 0.9209 - val_loss: 1.6465 - val_accuracy: 0.6069\n",
      "Epoch 38/40\n",
      "123/123 [==============================] - 130s 1s/step - loss: 0.2066 - accuracy: 0.9238 - val_loss: 2.1230 - val_accuracy: 0.6046\n",
      "Epoch 39/40\n",
      "123/123 [==============================] - 107s 870ms/step - loss: 0.2029 - accuracy: 0.9308 - val_loss: 1.6996 - val_accuracy: 0.6276\n",
      "Epoch 40/40\n",
      "123/123 [==============================] - 112s 908ms/step - loss: 0.1771 - accuracy: 0.9410 - val_loss: 1.7436 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cac07eaf0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(traindata, trainy, epochs=40, validation_split=0.1, initial_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 58, 48)        76848     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 58, 58, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 58, 58, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 29, 29, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 29, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 144)       62352     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 48)        62256     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25, 25, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 25, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 80)          96080     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 48)          96048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 48)          192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 96)                18528     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 582       \n",
      "=================================================================\n",
      "Total params: 413,910\n",
      "Trainable params: 413,622\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx=np.asarray(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=[]\n",
    "for i in range(len(testx)):\n",
    "    ttx=testx[i].reshape((64,64))\n",
    "    testdata.append(ttx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=np.asarray(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=testdata.reshape(len(testdata),64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy=testy.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy=np.asarray(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 3, 2, 4], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1087, 64, 64, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5035753846168518\n",
      "Test accuracy: 0.8767249584197998\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testdata, testy, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.415418e-17, 4.269471e-08, 9.539825e-07, 9.999808e-01,\n",
       "       1.753474e-05, 7.051959e-07], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9e78eef580>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testdata[0].reshape(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menu driven "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose 1 for webcam and 2 for image import2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp=input(\"Choose 1 for webcam and 2 for image import\")\n",
    "\n",
    "if inp==2:\n",
    "        frame=input(\"Enter image path: \")\n",
    "        i=Image.open(frame)\n",
    "        im2 = ImageOps.grayscale(i) \n",
    "        faces=face_cascade.detectMultiScale(np.array(im2),1.3,5)\n",
    "        if len(faces)!=0:\n",
    "            \n",
    "            (x,y,w,h)=faces[0]\n",
    "            crop=np.array(im2)[y:y+h, x:x+w]\n",
    "            s=cv2.resize(crop, (64, 64), interpolation=cv2.INTER_LINEAR)\n",
    "            norm_img = np.zeros((300, 300))\n",
    "            norm_img = cv2.normalize(s, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "            #PIL_image = Image.fromarray(np.uint8(norm_img)).convert('RGB')\n",
    "            PIL_image=np.asarray(norm_img)\n",
    "            #PIL_image=PIL_image[:,:,1]\n",
    "            #PIL_image.save(\"out.jpg\")\n",
    "            #plt.imshow(PIL_image)\n",
    "            #print(PIL_image.shape)\n",
    "            #model.predict(PIL_image)\n",
    "            PIL_image=PIL_image.reshape(1,64,64,1)\n",
    "            pre=model.predict(PIL_image)\n",
    "            o=np.argmax(pre)\n",
    "            print(o)\n",
    "        else:\n",
    "            print(\"Face not detected. Try again with another image (clearly visible at appropriate distance)\")\n",
    "else:\n",
    "    key = cv2. waitKey(1)\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        try:\n",
    "            check, frame = webcam.read()\n",
    "            print(check) #prints true as long as the webcam is running\n",
    "            print(frame) #prints matrix values of each framecd \n",
    "            cv2.imshow(\"Capturing\", frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('s'): \n",
    "                cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "                webcam.release()\n",
    "                img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "                img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "                cv2.waitKey(1650)\n",
    "                cv2.destroyAllWindows()\n",
    "                print(\"Processing image...\")\n",
    "                img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "                print(\"Converting RGB image to grayscale...\")\n",
    "                gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
    "                print(\"Converted RGB image to grayscale...\")\n",
    "                print(\"Resizing image to 64x64 scale...\")\n",
    "                img_ = cv2.resize(gray,(64,64))\n",
    "                print(\"Resized...\")\n",
    "                img_resized = cv2.imwrite(filename='saved_img.jpg', img=img_)\n",
    "                print(\"Image saved!\")\n",
    "\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                print(\"Turning off camera.\")\n",
    "                webcam.release()\n",
    "                print(\"Camera off.\")\n",
    "                print(\"Program ended.\")\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "        except(KeyboardInterrupt):\n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "            frame= \"saved_img.jpg\"\n",
    "            i=Image.open(frame)\n",
    "            im2 = ImageOps.grayscale(i) \n",
    "            faces=face_cascade.detectMultiScale(np.array(im2),1.3,5)\n",
    "            if len(faces)!=0:\n",
    "\n",
    "                (x,y,w,h)=faces[0]\n",
    "                crop=np.array(im2)[y:y+h, x:x+w]\n",
    "                s=cv2.resize(crop, (64, 64), interpolation=cv2.INTER_LINEAR)\n",
    "                norm_img = np.zeros((300, 300))\n",
    "                norm_img = cv2.normalize(s, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                #PIL_image = Image.fromarray(np.uint8(norm_img)).convert('RGB')\n",
    "                PIL_image=np.asarray(norm_img)\n",
    "                #PIL_image=PIL_image[:,:,1]\n",
    "                #PIL_image.save(\"out.jpg\")\n",
    "                #plt.imshow(PIL_image)\n",
    "                #print(PIL_image.shape)\n",
    "                #model.predict(PIL_image)\n",
    "                PIL_image=PIL_image.reshape(1,64,64,1)\n",
    "                pre=model.predict(PIL_image)\n",
    "                o=np.argmax(pre)\n",
    "                print(o)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter image pathdemo.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12288 into shape (64,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-63e41091bc9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#PIL_image = Image.fromarray(np.uint8(norm_img)).convert('RGB')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mPIL_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIL_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mPIL_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIL_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIL_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIL_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 12288 into shape (64,64,1)"
     ]
    }
   ],
   "source": [
    "frame=input(\"Enter image path\")\n",
    "i=Image.open(frame)\n",
    "#grayscale\n",
    "im2 = ImageOps.grayscale(i) \n",
    "faces=face_cascade.detectMultiScale(np.array(im2),1.3,5)\n",
    "(x,y,w,h)=faces[0]\n",
    "crop=np.array(im2)[y:y+h, x:x+w]\n",
    "s=cv2.resize(crop, (64, 64), interpolation=cv2.INTER_LINEAR)\n",
    "norm_img = np.zeros((300, 300))\n",
    "norm_img = cv2.normalize(s, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "#PIL_image = Image.fromarray(np.uint8(norm_img)).convert('RGB')\n",
    "PIL_image=np.asarray(PIL_image)\n",
    "PIL_image=PIL_image.reshape(64,64,1)\n",
    "print(PIL_image.shape)\n",
    "plt.imshow(PIL_image)\n",
    "print(type(PIL_image))\n",
    "#model.predict(PIL_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(PIL_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter image path: xyz.jpg\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "        frame=input(\"Enter image path: \")\n",
    "        i=Image.open(frame)\n",
    "        im2 = ImageOps.grayscale(i) \n",
    "        faces=face_cascade.detectMultiScale(np.array(im2),1.3,5)\n",
    "        if len(faces)!=0:\n",
    "            \n",
    "            (x,y,w,h)=faces[0]\n",
    "            crop=np.array(im2)[y:y+h, x:x+w]\n",
    "            s=cv2.resize(crop, (64, 64), interpolation=cv2.INTER_LINEAR)\n",
    "            norm_img = np.zeros((300, 300))\n",
    "            norm_img = cv2.normalize(s, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "            #PIL_image = Image.fromarray(np.uint8(norm_img)).convert('RGB')\n",
    "            PIL_image=np.asarray(norm_img)\n",
    "            #PIL_image=PIL_image[:,:,1]\n",
    "            #PIL_image.save(\"out.jpg\")\n",
    "            #plt.imshow(PIL_image)\n",
    "            #print(PIL_image.shape)\n",
    "            #model.predict(PIL_image)\n",
    "            PIL_image=PIL_image.reshape(1,64,64,1)\n",
    "            pre=model.predict(PIL_image)\n",
    "            o=np.argmax(pre)\n",
    "            print(o)\n",
    "        else:\n",
    "            print(\"Face not detected. Try again with anotheer image (clearly visible at appropriate distance)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [7 0 0]\n",
      "  [9 0 0]\n",
      "  [8 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [3 0 0]\n",
      "  [7 0 0]\n",
      "  [5 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [6 0 0]\n",
      "  [6 0 0]\n",
      "  [4 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "\n",
    "key = cv2. waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    try:\n",
    "        check, frame = webcam.read()\n",
    "        print(check) #prints true as long as the webcam is running\n",
    "        print(frame) #prints matrix values of each framecd \n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'): \n",
    "            cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "            webcam.release()\n",
    "            img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "            img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Processing image...\")\n",
    "            img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "            print(\"Converting RGB image to grayscale...\")\n",
    "            gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
    "            print(\"Converted RGB image to grayscale...\")\n",
    "            print(\"Resizing image to 64x64 scale...\")\n",
    "            img_ = cv2.resize(gray,(64,64))\n",
    "            print(\"Resized...\")\n",
    "            img_resized = cv2.imwrite(filename='saved_img.jpg', img=img_)\n",
    "            print(\"Image saved!\")\n",
    "        \n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "    except(KeyboardInterrupt):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "        frame= \"saved_img.jpg\"\n",
    "        i=Image.open(frame)\n",
    "        im2 = ImageOps.grayscale(i) \n",
    "        faces=face_cascade.detectMultiScale(np.array(im2),1.3,5)\n",
    "        if len(faces)!=0:\n",
    "            \n",
    "            (x,y,w,h)=faces[0]\n",
    "            crop=np.array(im2)[y:y+h, x:x+w]\n",
    "            s=cv2.resize(crop, (64, 64), interpolation=cv2.INTER_LINEAR)\n",
    "            norm_img = np.zeros((300, 300))\n",
    "            norm_img = cv2.normalize(s, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "            #PIL_image = Image.fromarray(np.uint8(norm_img)).convert('RGB')\n",
    "            PIL_image=np.asarray(norm_img)\n",
    "            #PIL_image=PIL_image[:,:,1]\n",
    "            #PIL_image.save(\"out.jpg\")\n",
    "            #plt.imshow(PIL_image)\n",
    "            #print(PIL_image.shape)\n",
    "            #model.predict(PIL_image)\n",
    "            PIL_image=PIL_image.reshape(1,64,64,1)\n",
    "            pre=model.predict(PIL_image)\n",
    "            o=np.argmax(pre)\n",
    "            print(o)\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Window\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    cv2.imshow(\"Window\", frame)\n",
    "\n",
    "    #This breaks on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
